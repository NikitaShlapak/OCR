{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d8aeca5b4a122b76"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13754/3196427401.py:5: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "2024-02-27 11:35:34.718689: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-27 11:35:34.718734: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-27 11:35:34.719593: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-27 11:35:34.724533: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-27 11:35:35.522609: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 11:35:36.542902: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-27 11:35:36.575372: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-02-27 11:35:36.575906: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import imutils\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "import cv2\n",
    "import keras_nlp\n"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-27T08:35:36.844026355Z",
     "start_time": "2024-02-27T08:35:33.988181959Z"
    }
   },
   "id": "initial_id",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "('2.15.0', '2.15.0')"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__, keras.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T08:35:36.849416965Z",
     "start_time": "2024-02-27T08:35:36.846612973Z"
    }
   },
   "id": "dbd05e6f2de9c890",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data load"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7b2bd656db70341"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@18.688] global loadsave.cpp:248 findDecoder imread_('data/letterlist.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m let \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mimread(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata/letterlist.jpg\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m let \u001B[38;5;241m=\u001B[39m \u001B[43mlet\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m15\u001B[39;49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m780\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m      3\u001B[0m num_letters \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m33\u001B[39m\n\u001B[1;32m      4\u001B[0m num_fonts \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m21\u001B[39m\n",
      "\u001B[0;31mTypeError\u001B[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "let = cv2.imread('data/letterlist.jpg', 0)\n",
    "let = let[15:780,:]\n",
    "num_letters = 33\n",
    "num_fonts = 21\n",
    "num_classes = 33\n",
    "input_shape = (32,32,1)\n",
    "\n",
    "def get_letter(font_num, letter_num):\n",
    "    letter = let[let.shape[0]//num_fonts*(font_num-1):let.shape[0]//num_fonts*font_num,\n",
    "           let.shape[1]//num_letters*(letter_num-1):let.shape[1]//num_letters*letter_num,\n",
    "           ]\n",
    "    return cv2.resize(letter, input_shape[:-1])\n",
    "\n",
    "def get_letter_variants(letter_num):\n",
    "        return let[:,\n",
    "           let.shape[1]//num_letters*(letter_num-1):let.shape[1]//num_letters*letter_num,\n",
    "           ]\n",
    "\n",
    "def get_font_variants(font_num):\n",
    "    return let[let.shape[0]//num_fonts*(font_num-1):let.shape[0]//num_fonts*font_num,\n",
    "           :,\n",
    "           ]\n",
    "test = get_letter(21,33)\n",
    "print(test.shape)\n",
    "plt.imshow(test, cmap='gray')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T08:35:52.832824779Z",
     "start_time": "2024-02-27T08:35:52.805809080Z"
    }
   },
   "id": "31ec1a4fad38584c",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Augmenters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a39579f6be053265"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 24\u001B[0m\n\u001B[1;32m     21\u001B[0m         noise \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mnormal(size\u001B[38;5;241m=\u001B[39m(letter\u001B[38;5;241m.\u001B[39mshape))\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mmax\u001B[39m\n\u001B[1;32m     22\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m letter\u001B[38;5;241m+\u001B[39mnoise\n\u001B[0;32m---> 24\u001B[0m plt\u001B[38;5;241m.\u001B[39mimshow(NoiseAugmenter(\u001B[38;5;241m1\u001B[39m)(\u001B[43mtest\u001B[49m)[\u001B[38;5;241m0\u001B[39m], cmap\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgray\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "class BaseAugmenter():\n",
    "    def __init__(self, chanse=0.5):\n",
    "        self.chance = chanse\n",
    "        \n",
    "    def __call__(self, img, *args, **kwargs):\n",
    "        augmented = False\n",
    "        if random.random()<= self.chance:\n",
    "            try:\n",
    "                img = self._apply(img, *args, **kwargs)\n",
    "                augmented = True\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            \n",
    "        return img, augmented\n",
    "    \n",
    "    def _apply(self, img, *args, **kwargs):\n",
    "        return img\n",
    "    \n",
    "class NoiseAugmenter(BaseAugmenter):\n",
    "    def _apply(self, letter, max=30):\n",
    "        noise = np.random.normal(size=(letter.shape))*max\n",
    "        return letter+noise\n",
    "    \n",
    "plt.imshow(NoiseAugmenter(1)(test)[0], cmap='gray')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T08:35:54.669637714Z",
     "start_time": "2024-02-27T08:35:54.651798140Z"
    }
   },
   "id": "5cae25a8ee446e09",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 12\u001B[0m\n\u001B[1;32m      9\u001B[0m             axis \u001B[38;5;241m=\u001B[39m random\u001B[38;5;241m.\u001B[39mrandom() \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m0.5\u001B[39m\n\u001B[1;32m     10\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mflip(letter, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mint\u001B[39m(axis))\n\u001B[0;32m---> 12\u001B[0m plt\u001B[38;5;241m.\u001B[39mimshow(FlipAugmenter(\u001B[38;5;241m1\u001B[39m)(\u001B[43mtest\u001B[49m)[\u001B[38;5;241m0\u001B[39m], cmap\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgray\u001B[39m\u001B[38;5;124m'\u001B[39m)  \n",
      "\u001B[0;31mNameError\u001B[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "class FlipAugmenter(BaseAugmenter):\n",
    "\n",
    "    def _apply(self, letter, mode='horizontal'):\n",
    "        if mode == 'horizontal':\n",
    "            return np.flip(letter, axis=0)\n",
    "        elif mode == 'vertical':\n",
    "            return np.flip(letter, axis=1)\n",
    "        elif mode == 'random':\n",
    "            axis = random.random() < 0.5\n",
    "            return np.flip(letter, axis=int(axis))\n",
    "        \n",
    "plt.imshow(FlipAugmenter(1)(test)[0], cmap='gray')  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T08:35:55.440107680Z",
     "start_time": "2024-02-27T08:35:55.433775232Z"
    }
   },
   "id": "672d728eaf429a83",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class RotationAugmenter(BaseAugmenter):\n",
    "    \n",
    "    def _apply(self, letter, angle=60):\n",
    "        image = np.zeros_like(letter) + 255 - letter\n",
    "        rotated = imutils.rotate_bound(image, angle)\n",
    "        rotated = np.zeros_like(rotated) + 255 - rotated\n",
    "        rotated = cv2.resize(rotated, (letter.shape[1], letter.shape[0]))\n",
    "        return rotated\n",
    "rotated = RotationAugmenter(1)(test)[0]\n",
    "plt.imshow(rotated, cmap='gray')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-27T08:35:37.157018058Z"
    }
   },
   "id": "c4571be9d9e02307",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class BlurAugmenter(BaseAugmenter):\n",
    "    \n",
    "    def _apply(self, letter, kernel_size=3):\n",
    "        return cv2.medianBlur(letter, kernel_size)\n",
    "    \n",
    "plt.imshow(BlurAugmenter(1)(test)[0], cmap='gray')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-27T08:35:37.157087991Z"
    }
   },
   "id": "1c86412a40bea359",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class MultipleAugmenter():\n",
    "    NOISE_CHANCE = 0.1\n",
    "    NOISE_HARDNESS = 20\n",
    "    \n",
    "    FLIP_CHANCE = 0.3\n",
    "    \n",
    "    ROTATE_CHANCE = 0.15\n",
    "    \n",
    "    BLUR_CHANCE = 0.1\n",
    "    BLUR_HARD_CHANCE = 0.05\n",
    "    \n",
    "    images = []\n",
    "    captions = []\n",
    "    \n",
    "    def __init__(self, images, captions):\n",
    "        self.images_orig = images\n",
    "        self.captions_orig = captions\n",
    "        self.augmenters = [\n",
    "            FlipAugmenter(self.FLIP_CHANCE),\n",
    "            RotationAugmenter(self.ROTATE_CHANCE),\n",
    "            BlurAugmenter(self.BLUR_CHANCE),\n",
    "            BlurAugmenter(self.BLUR_HARD_CHANCE),\n",
    "            \n",
    "        ]\n",
    "        self.noise = (NoiseAugmenter(self.NOISE_CHANCE), self.NOISE_HARDNESS)\n",
    "        \n",
    "        self.augment_args = [\n",
    "            ['random'],\n",
    "            [],\n",
    "            [3],\n",
    "            [5],\n",
    "\n",
    "        ]    \n",
    "    \n",
    "    def random_augment(self, rounds = 1, seed = 42, save_last=False):\n",
    "        random.seed(seed)\n",
    "        \n",
    "        images = self.images_orig\n",
    "        captions = self.captions_orig\n",
    "        \n",
    "        for _ in range(rounds):\n",
    "            print(len(images))\n",
    "            num_images = len(images)\n",
    "            for n in range(num_images):\n",
    "                image = images[n]\n",
    "                caption = captions[n]\n",
    "                \n",
    "                for n, aug in enumerate(self.augmenters):\n",
    "                    aug_args = self.augment_args[n]\n",
    "                    if not aug_args:\n",
    "                        aug_args = [random.randint(-15,15)]\n",
    "                    image, augmented = aug(image, *aug_args)\n",
    "                    if augmented:\n",
    "                        images.append(image)\n",
    "                        captions.append(caption)\n",
    "                    \n",
    "            if save_last:\n",
    "                images = images[num_images:]\n",
    "                captions = captions[num_images:]\n",
    "        \n",
    "\n",
    "                \n",
    "        self.images = images\n",
    "        self.captions = captions        \n",
    "        self._apply_noise()\n",
    "        self._normalize()\n",
    "        \n",
    "    def _apply_noise(self):\n",
    "        for n, im in enumerate(self.images):\n",
    "            noise_augmenter, hardeness = self.noise\n",
    "            image, augmented = noise_augmenter(im, hardeness)\n",
    "            if augmented:\n",
    "                self.images[n] = image        \n",
    "        \n",
    "    def _normalize(self):\n",
    "        for n, im in enumerate(self.images):\n",
    "            im = np.array(im)\n",
    "            self.images[n] = im/im.max()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-27T08:35:37.157147334Z"
    }
   },
   "id": "ea46e76b869612d0",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preparation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "858fd0191b301e8a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "images = []\n",
    "captions = []\n",
    "captions_base = \"Ё Й Ц У К Е Н Г Ш Щ З Х Ъ Ф Ы В А П Р О Л Д Ж Э Я Ч С М И Т Ь Б Ю\".split(' ')\n",
    "for i in range(1, num_fonts+1):\n",
    "    for j in range(1, num_letters+1):\n",
    "        images.append(get_letter(i,j))\n",
    "        captions.append(captions_base[j-1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-27T08:35:37.157205885Z"
    }
   },
   "id": "b889de298188a602",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.imshow(images[10], cmap='gray')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-27T08:35:37.157263725Z"
    }
   },
   "id": "9c6ecb2699a696ab",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "len(images)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-27T08:35:37.157388703Z"
    }
   },
   "id": "2e67bf6b26acb86b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "aug = MultipleAugmenter(images.copy(), captions.copy())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-27T08:35:37.157538508Z"
    }
   },
   "id": "fa972db114e4c128",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "aug.random_augment(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-27T08:35:37.157588172Z"
    }
   },
   "id": "7fe2fc47020e1146",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "n = 1000\n",
    "print(aug.captions[n])\n",
    "plt.imshow(aug.images[n], cmap='gray')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-27T08:35:37.157629160Z"
    }
   },
   "id": "3239f851deaf6a22",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "np.array(aug.images).shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-27T08:35:37.157669387Z"
    }
   },
   "id": "39a95932e48594c4",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dda537d94b7fb63c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x_data = np.array(aug.images)\n",
    "x_data = x_data.reshape(*x_data.shape, 1)\n",
    "x_data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-27T08:35:37.157709793Z"
    }
   },
   "id": "af899195b0ba1837",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "classes = list(map(captions_base.index, aug.captions))\n",
    "y_data = keras.utils.to_categorical(classes, num_classes=num_letters)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-27T08:35:37.157750821Z"
    }
   },
   "id": "1fe9946e9c91f535",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "311fefbac5ef98cc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_aug = MultipleAugmenter(images.copy(), captions.copy())\n",
    "test_aug.random_augment(3, 65, 0)\n",
    "len(test_aug.images), len(test_aug.captions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-27T08:35:37.157791338Z"
    }
   },
   "id": "d3e86fc400b72002",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_x_data = np.array(test_aug.images)\n",
    "# test_x_data = test_x_data.reshape(*test_x_data.shape)\n",
    "\n",
    "test_classes = list(map(captions_base.index, test_aug.captions))\n",
    "test_y_data = keras.utils.to_categorical(test_classes, num_classes=num_letters)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-27T08:35:37.157831244Z"
    }
   },
   "id": "d7346d5ae5b7ad49",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Callbacks"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "add44ae6827d72f1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, min_delta = 1e-3,\n",
    "                              patience=3, min_lr=1e-10)\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-6, patience=7)\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir=\"./logs\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-27T08:35:37.157872433Z"
    }
   },
   "id": "94ed6777f2bd6bbc",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Transformer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "699a1f6876c4c15d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"super_model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 200, 200)]           0         []                            \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)         (None, 40000)                0         ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)     (None, 40000, 1)             40000     ['flatten_4[0][0]']           \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)         (None, 200, 200)             0         ['embedding_2[0][0]']         \n",
      "                                                                                                  \n",
      " add_2 (Add)                 (None, 200, 200)             0         ['input_3[0][0]',             \n",
      "                                                                     'reshape_2[0][0]']           \n",
      "                                                                                                  \n",
      " transformer_encoder_8 (Tra  (None, 200, 200)             566000    ['add_2[0][0]']               \n",
      " nsformerEncoder)                                                                                 \n",
      "                                                                                                  \n",
      " transformer_encoder_9 (Tra  (None, 200, 200)             566000    ['transformer_encoder_8[0][0]'\n",
      " nsformerEncoder)                                                   ]                             \n",
      "                                                                                                  \n",
      " transformer_encoder_10 (Tr  (None, 200, 200)             566000    ['transformer_encoder_9[0][0]'\n",
      " ansformerEncoder)                                                  ]                             \n",
      "                                                                                                  \n",
      " transformer_encoder_11 (Tr  (None, 200, 200)             566000    ['transformer_encoder_10[0][0]\n",
      " ansformerEncoder)                                                  ']                            \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)         (None, 40000)                0         ['transformer_encoder_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 1024)                 4096102   ['flatten_5[0][0]']           \n",
      "                                                          4                                       \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 512)                  524800    ['dense_7[0][0]']             \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 256)                  131328    ['dense_8[0][0]']             \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (None, 33)                   8481      ['dense_9[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 43929633 (167.58 MB)\n",
      "Trainable params: 43929633 (167.58 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (200,200)\n",
    "num_letters = 33\n",
    "inputs = keras.Input(shape=input_shape )\n",
    "\n",
    "flat = keras.layers.Flatten()(inputs)\n",
    "\n",
    "emb = keras.layers.Embedding(input_shape[0]*input_shape[1], 1)(flat)\n",
    "\n",
    "reshaped2 = keras.layers.Reshape(input_shape)(emb)\n",
    "\n",
    "embedded = keras.layers.Add()([inputs, reshaped2])\n",
    "\n",
    "encoded = keras_nlp.layers.TransformerEncoder(intermediate_dim=1024, num_heads=24)(embedded)\n",
    "encoded = keras_nlp.layers.TransformerEncoder(intermediate_dim=1024, num_heads=24)(encoded)\n",
    "encoded = keras_nlp.layers.TransformerEncoder(intermediate_dim=1024, num_heads=24)(encoded)\n",
    "encoded = keras_nlp.layers.TransformerEncoder(intermediate_dim=1024, num_heads=24)(encoded)\n",
    "dense = keras.layers.Flatten()(encoded)\n",
    "dense = keras.layers.Dense(1024, activation='relu')(dense)\n",
    "dense = keras.layers.Dense(512, activation='relu')(dense)\n",
    "dense = keras.layers.Dense(256, activation='relu')(dense)\n",
    "outputs = keras.layers.Dense(num_letters, activation='softmax')(dense)\n",
    "\n",
    "\n",
    "vit_model = keras.Model(inputs=inputs, outputs=outputs, name='super_model')\n",
    "vit_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-27T08:37:01.453512835Z",
     "start_time": "2024-02-27T08:37:01.038730003Z"
    }
   },
   "id": "bd1275e7cffe0140",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "vit_model.compile(loss='categorical_crossentropy', metrics=['categorical_accuracy'], optimizer='adam')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "f5d252388566fa4c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "n_figs = 10\n",
    "fig, ax = plt.subplots(nrows=4, ncols=n_figs//2)\n",
    "for i in range(n_figs):\n",
    "    img = aug.images[i]\n",
    "    img2 = vit_model.predict(img.reshape((1,*input_shape)))[0]\n",
    "\n",
    "    ax[int(i>=5)*2+0,i- (5*int(i>=5))].imshow(img, cmap = 'gray')\n",
    "    ax[int(i>=5)*2+1,i- (5*int(i>=5))].imshow(img2, cmap = 'gray')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "5e399d22a4477856",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "his = vit_model.fit(x_data, y_data,\n",
    "          epochs=50,\n",
    "          batch_size=128,\n",
    "          shuffle=True,\n",
    "          validation_split=0.2,\n",
    "          callbacks=[reduce_lr, early_stop, tensorboard],\n",
    "                )"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "e96b3a3d680c6286",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "his_df = pd.DataFrame(his.history)\n",
    "his_df[['categorical_accuracy', 'val_categorical_accuracy']].plot()\n",
    "(his_df['learning_rate'] * 1000).plot()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "6dc7c3ff9671a4b4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "vit_model.evaluate(test_x_data.reshape((*test_x_data.shape, 1)), test_y_data)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "20f86aa79f2d9786",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_x_data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "2a5a116c1322a756",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "y_pred = vit_model.predict(test_x_data).argmax(axis=1)\n",
    "mat = np.zeros(shape=(num_letters,num_letters))\n",
    "for i in range(len(y_pred)):\n",
    "    true_ind = test_classes[i]\n",
    "    pred_ind = y_pred[i]    \n",
    "    mat[true_ind, pred_ind]+=1\n",
    "\n",
    "mat=mat/mat.sum(axis=0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "ax.matshow(mat, cmap='Blues')\n",
    "ax.set_xticks(range(len(captions_base)), captions_base)\n",
    "ax.set_yticks(range(len(captions_base)), captions_base)\n",
    "for i in range(len(captions_base)):\n",
    "    for j in range(len(captions_base)):\n",
    "        c = mat[j,i]\n",
    "        ax.text(i, j, f'{c:.2f}', va='center', ha='center')\n",
    "ax.set_xlabel('True letters', fontsize=15)\n",
    "ax.set_ylabel('Predicted letters', fontsize=15)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "1905c46bd6fedd38",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "vit_model.save('models/vit_letter_recognizer.keras')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "f00792ba4787a5dd",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
