{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Vit (from ofdocs)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60bfc8ae10e2d8f8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6f4f926052df5bb"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-29 12:13:55.591722: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-29 12:13:55.593017: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-29 12:13:55.625135: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-29 12:13:56.354601: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": "('2.16.0-dev20240101', '3.0.0')"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import ops\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.__version__, keras.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T09:13:57.259934007Z",
     "start_time": "2024-01-29T09:13:55.357769966Z"
    }
   },
   "id": "9546a90916d06dfd",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Download data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49b087cd38ba6eee"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3) - y_train shape: (50000, 1)\n",
      "x_test shape: (10000, 32, 32, 3) - y_test shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "num_classes = 100\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T09:13:57.539675448Z",
     "start_time": "2024-01-29T09:13:57.261756114Z"
    }
   },
   "id": "d80cd6f23956f20a",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setting parameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f824d82ccc0765f9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 64\n",
    "num_epochs = 10  # For real training, use num_epochs=100. 10 is a test value\n",
    "image_size = 64  # We'll resize input images to this size\n",
    "patch_size = 8  # Size of the patches to be extract from the input images\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "num_heads = 4\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]  # Size of the transformer layers\n",
    "transformer_layers = 4\n",
    "mlp_head_units = [\n",
    "    1024,\n",
    "    512,\n",
    "]  # Size of the dense layers of the final classifier\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T09:23:11.186834586Z",
     "start_time": "2024-01-29T09:23:11.174294085Z"
    }
   },
   "id": "9506089c0d74ea81",
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tools"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "227db3147ecbadeb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data augmentation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "412f2431d38f2a4d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Normalization(),\n",
    "        layers.Resizing(image_size, image_size),\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(factor=0.02),\n",
    "        layers.RandomZoom(height_factor=0.2, width_factor=0.2),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "# Compute the mean and the variance of the training data for normalization.\n",
    "data_augmentation.layers[0].adapt(x_train)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T09:23:14.156146175Z",
     "start_time": "2024-01-29T09:23:12.934960581Z"
    }
   },
   "id": "ad072d2ed7f9c576",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=keras.activations.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T09:23:14.161434014Z",
     "start_time": "2024-01-29T09:23:14.155622645Z"
    }
   },
   "id": "30f7ae2d6885a49d",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        input_shape = ops.shape(images)\n",
    "        batch_size = input_shape[0]\n",
    "        height = input_shape[1]\n",
    "        width = input_shape[2]\n",
    "        channels = input_shape[3]\n",
    "        num_patches_h = height // self.patch_size\n",
    "        num_patches_w = width // self.patch_size\n",
    "        patches = keras.ops.image.extract_patches(images, size=self.patch_size)\n",
    "        patches = ops.reshape(\n",
    "            patches,\n",
    "            (\n",
    "                batch_size,\n",
    "                num_patches_h * num_patches_w,\n",
    "                self.patch_size * self.patch_size * channels,\n",
    "            ),\n",
    "        )\n",
    "        return patches\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"patch_size\": self.patch_size})\n",
    "        return config\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T09:23:14.162134508Z",
     "start_time": "2024-01-29T09:23:14.159772672Z"
    }
   },
   "id": "8d0180dea9da238d",
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualising Patches"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64168a64af6db8cb"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling Patches.call().\n\n\u001B[1mcannot compute Conv2D as input #1(zero-based) was expected to be a int32 tensor but is a float tensor [Op:Conv2D] name: \u001B[0m\n\nArguments received by Patches.call():\n  • images=tf.Tensor(shape=(1, 64, 64, 3), dtype=int32)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[24], line 9\u001B[0m\n\u001B[1;32m      4\u001B[0m plt\u001B[38;5;241m.\u001B[39maxis(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moff\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      6\u001B[0m resized_image \u001B[38;5;241m=\u001B[39m ops\u001B[38;5;241m.\u001B[39mimage\u001B[38;5;241m.\u001B[39mresize(\n\u001B[1;32m      7\u001B[0m     ops\u001B[38;5;241m.\u001B[39mconvert_to_tensor([image]), size\u001B[38;5;241m=\u001B[39m(image_size, image_size)\n\u001B[1;32m      8\u001B[0m )\n\u001B[0;32m----> 9\u001B[0m patches \u001B[38;5;241m=\u001B[39m \u001B[43mPatches\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpatch_size\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresized_image\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mImage size: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mimage_size\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m X \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mimage_size\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPatch size: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpatch_size\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m X \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpatch_size\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/scientificProject1/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:123\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    120\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m    122\u001B[0m     \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m--> 123\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    125\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "Cell \u001B[0;32mIn[23], line 14\u001B[0m, in \u001B[0;36mPatches.call\u001B[0;34m(self, images)\u001B[0m\n\u001B[1;32m     12\u001B[0m num_patches_h \u001B[38;5;241m=\u001B[39m height \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpatch_size\n\u001B[1;32m     13\u001B[0m num_patches_w \u001B[38;5;241m=\u001B[39m width \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpatch_size\n\u001B[0;32m---> 14\u001B[0m patches \u001B[38;5;241m=\u001B[39m \u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextract_patches\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpatch_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m patches \u001B[38;5;241m=\u001B[39m ops\u001B[38;5;241m.\u001B[39mreshape(\n\u001B[1;32m     16\u001B[0m     patches,\n\u001B[1;32m     17\u001B[0m     (\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     21\u001B[0m     ),\n\u001B[1;32m     22\u001B[0m )\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m patches\n",
      "\u001B[0;31mInvalidArgumentError\u001B[0m: Exception encountered when calling Patches.call().\n\n\u001B[1mcannot compute Conv2D as input #1(zero-based) was expected to be a int32 tensor but is a float tensor [Op:Conv2D] name: \u001B[0m\n\nArguments received by Patches.call():\n  • images=tf.Tensor(shape=(1, 64, 64, 3), dtype=int32)"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 400x400 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "image = x_train[np.random.choice(range(x_train.shape[0]))]\n",
    "plt.imshow(image.astype(\"uint8\"))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "resized_image = ops.image.resize(\n",
    "    ops.convert_to_tensor([image]), size=(image_size, image_size)\n",
    ")\n",
    "patches = Patches(patch_size)(resized_image)\n",
    "print(f\"Image size: {image_size} X {image_size}\")\n",
    "print(f\"Patch size: {patch_size} X {patch_size}\")\n",
    "print(f\"Patches per image: {patches.shape[1]}\")\n",
    "print(f\"Elements per patch: {patches.shape[-1]}\")\n",
    "\n",
    "n = int(np.sqrt(patches.shape[1]))\n",
    "plt.figure(figsize=(4, 4))\n",
    "for i, patch in enumerate(patches[0]):\n",
    "    ax = plt.subplot(n, n, i + 1)\n",
    "    patch_img = ops.reshape(patch, (patch_size, patch_size, 3))\n",
    "    plt.imshow(ops.convert_to_numpy(patch_img).astype(\"uint8\"))\n",
    "    plt.axis(\"off\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T09:23:15.503952499Z",
     "start_time": "2024-01-29T09:23:15.451799889Z"
    }
   },
   "id": "c44d60dc928ace23",
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "### PatchEncoder layer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f322a2f09c22a4e8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super().__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = ops.expand_dims(\n",
    "            ops.arange(start=0, stop=self.num_patches, step=1), axis=0\n",
    "        )\n",
    "        projected_patches = self.projection(patch)\n",
    "        encoded = projected_patches + self.position_embedding(positions)\n",
    "        return encoded\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"num_patches\": self.num_patches})\n",
    "        return config\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T09:23:27.234451879Z",
     "start_time": "2024-01-29T09:23:27.192252036Z"
    }
   },
   "id": "32de5912acf61eb0",
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cdb358805da91d89"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[1mModel: \"functional_10\"\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_10\"</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001B[1m \u001B[0m\u001B[1mLayer (type)       \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape     \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mParam #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to        \u001B[0m\u001B[1m \u001B[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_5       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m, \u001B[38;5;34m32\u001B[0m, \u001B[38;5;34m3\u001B[0m) │       \u001B[38;5;34m0\u001B[0m │ -                    │\n│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ data_augmentation   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m3\u001B[0m) │       \u001B[38;5;34m7\u001B[0m │ input_layer_5[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n│ (\u001B[38;5;33mSequential\u001B[0m)        │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ patches_6 (\u001B[38;5;33mPatches\u001B[0m) │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m192\u001B[0m)   │       \u001B[38;5;34m0\u001B[0m │ data_augmentation[\u001B[38;5;34m0\u001B[0m… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ patch_encoder_3     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │  \u001B[38;5;34m16,448\u001B[0m │ patches_6[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]      │\n│ (\u001B[38;5;33mPatchEncoder\u001B[0m)      │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ layer_normalizatio… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │     \u001B[38;5;34m128\u001B[0m │ patch_encoder_3[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m…\u001B[0m │\n│ (\u001B[38;5;33mLayerNormalizatio…\u001B[0m │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ multi_head_attenti… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │  \u001B[38;5;34m66,368\u001B[0m │ layer_normalization… │\n│ (\u001B[38;5;33mMultiHeadAttentio…\u001B[0m │                   │         │ layer_normalization… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ add_48 (\u001B[38;5;33mAdd\u001B[0m)        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │       \u001B[38;5;34m0\u001B[0m │ multi_head_attentio… │\n│                     │                   │         │ patch_encoder_3[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m…\u001B[0m │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ layer_normalizatio… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │     \u001B[38;5;34m128\u001B[0m │ add_48[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]         │\n│ (\u001B[38;5;33mLayerNormalizatio…\u001B[0m │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_61 (\u001B[38;5;33mDense\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m128\u001B[0m)   │   \u001B[38;5;34m8,320\u001B[0m │ layer_normalization… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_82          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m128\u001B[0m)   │       \u001B[38;5;34m0\u001B[0m │ dense_61[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]       │\n│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_62 (\u001B[38;5;33mDense\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │   \u001B[38;5;34m8,256\u001B[0m │ dropout_82[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_83          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │       \u001B[38;5;34m0\u001B[0m │ dense_62[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]       │\n│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ add_49 (\u001B[38;5;33mAdd\u001B[0m)        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │       \u001B[38;5;34m0\u001B[0m │ dropout_83[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m],    │\n│                     │                   │         │ add_48[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]         │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ layer_normalizatio… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │     \u001B[38;5;34m128\u001B[0m │ add_49[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]         │\n│ (\u001B[38;5;33mLayerNormalizatio…\u001B[0m │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ multi_head_attenti… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │  \u001B[38;5;34m66,368\u001B[0m │ layer_normalization… │\n│ (\u001B[38;5;33mMultiHeadAttentio…\u001B[0m │                   │         │ layer_normalization… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ add_50 (\u001B[38;5;33mAdd\u001B[0m)        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │       \u001B[38;5;34m0\u001B[0m │ multi_head_attentio… │\n│                     │                   │         │ add_49[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]         │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ layer_normalizatio… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │     \u001B[38;5;34m128\u001B[0m │ add_50[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]         │\n│ (\u001B[38;5;33mLayerNormalizatio…\u001B[0m │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_63 (\u001B[38;5;33mDense\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m128\u001B[0m)   │   \u001B[38;5;34m8,320\u001B[0m │ layer_normalization… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_85          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m128\u001B[0m)   │       \u001B[38;5;34m0\u001B[0m │ dense_63[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]       │\n│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_64 (\u001B[38;5;33mDense\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │   \u001B[38;5;34m8,256\u001B[0m │ dropout_85[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_86          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │       \u001B[38;5;34m0\u001B[0m │ dense_64[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]       │\n│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ add_51 (\u001B[38;5;33mAdd\u001B[0m)        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │       \u001B[38;5;34m0\u001B[0m │ dropout_86[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m],    │\n│                     │                   │         │ add_50[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]         │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ layer_normalizatio… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │     \u001B[38;5;34m128\u001B[0m │ add_51[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]         │\n│ (\u001B[38;5;33mLayerNormalizatio…\u001B[0m │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ multi_head_attenti… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │  \u001B[38;5;34m66,368\u001B[0m │ layer_normalization… │\n│ (\u001B[38;5;33mMultiHeadAttentio…\u001B[0m │                   │         │ layer_normalization… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ add_52 (\u001B[38;5;33mAdd\u001B[0m)        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │       \u001B[38;5;34m0\u001B[0m │ multi_head_attentio… │\n│                     │                   │         │ add_51[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]         │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ layer_normalizatio… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │     \u001B[38;5;34m128\u001B[0m │ add_52[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]         │\n│ (\u001B[38;5;33mLayerNormalizatio…\u001B[0m │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_65 (\u001B[38;5;33mDense\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m128\u001B[0m)   │   \u001B[38;5;34m8,320\u001B[0m │ layer_normalization… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_88          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m128\u001B[0m)   │       \u001B[38;5;34m0\u001B[0m │ dense_65[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]       │\n│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_66 (\u001B[38;5;33mDense\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │   \u001B[38;5;34m8,256\u001B[0m │ dropout_88[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_89          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │       \u001B[38;5;34m0\u001B[0m │ dense_66[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]       │\n│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ add_53 (\u001B[38;5;33mAdd\u001B[0m)        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │       \u001B[38;5;34m0\u001B[0m │ dropout_89[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m],    │\n│                     │                   │         │ add_52[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]         │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ layer_normalizatio… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │     \u001B[38;5;34m128\u001B[0m │ add_53[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]         │\n│ (\u001B[38;5;33mLayerNormalizatio…\u001B[0m │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ multi_head_attenti… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │  \u001B[38;5;34m66,368\u001B[0m │ layer_normalization… │\n│ (\u001B[38;5;33mMultiHeadAttentio…\u001B[0m │                   │         │ layer_normalization… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ add_54 (\u001B[38;5;33mAdd\u001B[0m)        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │       \u001B[38;5;34m0\u001B[0m │ multi_head_attentio… │\n│                     │                   │         │ add_53[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]         │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ layer_normalizatio… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │     \u001B[38;5;34m128\u001B[0m │ add_54[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]         │\n│ (\u001B[38;5;33mLayerNormalizatio…\u001B[0m │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_67 (\u001B[38;5;33mDense\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m128\u001B[0m)   │   \u001B[38;5;34m8,320\u001B[0m │ layer_normalization… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_91          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m128\u001B[0m)   │       \u001B[38;5;34m0\u001B[0m │ dense_67[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]       │\n│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_68 (\u001B[38;5;33mDense\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │   \u001B[38;5;34m8,256\u001B[0m │ dropout_91[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_92          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │       \u001B[38;5;34m0\u001B[0m │ dense_68[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]       │\n│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ add_55 (\u001B[38;5;33mAdd\u001B[0m)        │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │       \u001B[38;5;34m0\u001B[0m │ dropout_92[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m],    │\n│                     │                   │         │ add_54[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]         │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ layer_normalizatio… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m64\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │     \u001B[38;5;34m128\u001B[0m │ add_55[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]         │\n│ (\u001B[38;5;33mLayerNormalizatio…\u001B[0m │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ flatten_3 (\u001B[38;5;33mFlatten\u001B[0m) │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m4096\u001B[0m)      │       \u001B[38;5;34m0\u001B[0m │ layer_normalization… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_93          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m4096\u001B[0m)      │       \u001B[38;5;34m0\u001B[0m │ flatten_3[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]      │\n│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_69 (\u001B[38;5;33mDense\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1024\u001B[0m)      │ \u001B[38;5;34m4,195,…\u001B[0m │ dropout_93[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_94          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1024\u001B[0m)      │       \u001B[38;5;34m0\u001B[0m │ dense_69[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]       │\n│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_70 (\u001B[38;5;33mDense\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m512\u001B[0m)       │ \u001B[38;5;34m524,800\u001B[0m │ dropout_94[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_95          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m512\u001B[0m)       │       \u001B[38;5;34m0\u001B[0m │ dense_70[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]       │\n│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_71 (\u001B[38;5;33mDense\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m100\u001B[0m)       │  \u001B[38;5;34m51,300\u001B[0m │ dropout_95[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n└─────────────────────┴───────────────────┴─────────┴──────────────────────┘\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\"> Param # </span>┃<span style=\"font-weight: bold\"> Connected to         </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_5       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>) │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ data_augmentation   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>) │       <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ patches_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Patches</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)   │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ data_augmentation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ patch_encoder_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │ patches_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PatchEncoder</span>)      │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ patch_encoder_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">66,368</span> │ layer_normalization… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │         │ layer_normalization… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ add_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attentio… │\n│                     │                   │         │ patch_encoder_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_48[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_61 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │   <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_82          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_61[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_62 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │   <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_82[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_83          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_62[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ add_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_83[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n│                     │                   │         │ add_48[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_49[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">66,368</span> │ layer_normalization… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │         │ layer_normalization… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ add_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attentio… │\n│                     │                   │         │ add_49[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_63 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │   <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_85          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_63[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_64 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │   <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_85[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_86          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_64[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ add_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_86[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n│                     │                   │         │ add_50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">66,368</span> │ layer_normalization… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │         │ layer_normalization… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ add_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attentio… │\n│                     │                   │         │ add_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_65 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │   <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_88          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_65[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │   <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_88[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_89          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_66[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ add_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_89[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n│                     │                   │         │ add_52[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_53[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">66,368</span> │ layer_normalization… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │         │ layer_normalization… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ add_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attentio… │\n│                     │                   │         │ add_53[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_54[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │   <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_91          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_67[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_68 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │   <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_91[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_92          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_68[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ add_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_92[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n│                     │                   │         │ add_54[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_55[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_93          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_69 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">4,195,…</span> │ dropout_93[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_94          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_69[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_70 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │ dropout_94[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_95          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_70[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_71 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">51,300</span> │ dropout_95[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n└─────────────────────┴───────────────────┴─────────┴──────────────────────┘\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m5,120,811\u001B[0m (19.53 MB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,120,811</span> (19.53 MB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m5,120,804\u001B[0m (19.53 MB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,120,804</span> (19.53 MB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m7\u001B[0m (32.00 B)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7</span> (32.00 B)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def create_vit_classifier():\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    # Augment data.\n",
    "    augmented = data_augmentation(inputs)\n",
    "    # Create patches.\n",
    "    patches = Patches(patch_size)(augmented)\n",
    "    # Encode patches.\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        # Skip connection 2.\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor.\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    representation = layers.Dropout(0.5)(representation)\n",
    "    # Add MLP.\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    # Classify outputs.\n",
    "    logits = layers.Dense(num_classes)(features)\n",
    "    # Create the Keras model.\n",
    "    model = keras.Model(inputs=inputs, outputs=logits)\n",
    "    return model\n",
    "vit_classifier = create_vit_classifier()\n",
    "vit_classifier.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T09:23:29.069008503Z",
     "start_time": "2024-01-29T09:23:28.885010602Z"
    }
   },
   "id": "829f6b5af2a51eb1",
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Run"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1050709c31119a2"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m 87/704\u001B[0m \u001B[32m━━\u001B[0m\u001B[37m━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m1:40\u001B[0m 163ms/step - accuracy: 0.0130 - loss: 5.5920 - top-5-accuracy: 0.0610"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[27], line 41\u001B[0m\n\u001B[1;32m     35\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTest top 5 accuracy: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mround\u001B[39m(top_5_accuracy\u001B[38;5;250m \u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m100\u001B[39m,\u001B[38;5;250m \u001B[39m\u001B[38;5;241m2\u001B[39m)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     37\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m history\n\u001B[0;32m---> 41\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mrun_experiment\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvit_classifier\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mplot_history\u001B[39m(item):\n\u001B[1;32m     45\u001B[0m     plt\u001B[38;5;241m.\u001B[39mplot(history\u001B[38;5;241m.\u001B[39mhistory[item], label\u001B[38;5;241m=\u001B[39mitem)\n",
      "Cell \u001B[0;32mIn[27], line 23\u001B[0m, in \u001B[0;36mrun_experiment\u001B[0;34m(model)\u001B[0m\n\u001B[1;32m     15\u001B[0m checkpoint_filepath \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/tmp/checkpoint.weights.h5\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     16\u001B[0m checkpoint_callback \u001B[38;5;241m=\u001B[39m keras\u001B[38;5;241m.\u001B[39mcallbacks\u001B[38;5;241m.\u001B[39mModelCheckpoint(\n\u001B[1;32m     17\u001B[0m     checkpoint_filepath,\n\u001B[1;32m     18\u001B[0m     monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mval_accuracy\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     19\u001B[0m     save_best_only\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m     20\u001B[0m     save_weights_only\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m     21\u001B[0m )\n\u001B[0;32m---> 23\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     24\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     25\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     26\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     27\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mcheckpoint_callback\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     30\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     32\u001B[0m model\u001B[38;5;241m.\u001B[39mload_weights(checkpoint_filepath)\n\u001B[1;32m     33\u001B[0m _, accuracy, top_5_accuracy \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mevaluate(x_test, y_test)\n",
      "File \u001B[0;32m~/PycharmProjects/scientificProject1/.venv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:118\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    116\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    117\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 118\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    119\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    120\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/PycharmProjects/scientificProject1/.venv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:323\u001B[0m, in \u001B[0;36mTensorFlowTrainer.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001B[0m\n\u001B[1;32m    321\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step, iterator \u001B[38;5;129;01min\u001B[39;00m epoch_iterator\u001B[38;5;241m.\u001B[39menumerate_epoch():\n\u001B[1;32m    322\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m--> 323\u001B[0m     logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    324\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_end(\n\u001B[1;32m    325\u001B[0m         step, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pythonify_logs(logs)\n\u001B[1;32m    326\u001B[0m     )\n\u001B[1;32m    327\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstop_training:\n",
      "File \u001B[0;32m~/PycharmProjects/scientificProject1/.venv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/PycharmProjects/scientificProject1/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    830\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    832\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 833\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    835\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    836\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/PycharmProjects/scientificProject1/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    875\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    876\u001B[0m \u001B[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001B[39;00m\n\u001B[1;32m    877\u001B[0m \u001B[38;5;66;03m# run the first trace but we should fail if variables are created.\u001B[39;00m\n\u001B[0;32m--> 878\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    879\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_variable_creation_config\u001B[49m\n\u001B[1;32m    880\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    881\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables:\n\u001B[1;32m    882\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCreating variables on a non-first call to a function\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    883\u001B[0m                    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m decorated with tf.function.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/scientificProject1/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[0;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[1;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/scientificProject1/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[1;32m   1318\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1319\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1320\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1321\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1322\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_preflattened\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1323\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1324\u001B[0m     args,\n\u001B[1;32m   1325\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1326\u001B[0m     executing_eagerly)\n\u001B[1;32m   1327\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/PycharmProjects/scientificProject1/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001B[0m, in \u001B[0;36mAtomicFunction.call_preflattened\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    215\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 216\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    217\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[0;32m~/PycharmProjects/scientificProject1/.venv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001B[0m, in \u001B[0;36mAtomicFunction.call_flat\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[1;32m    250\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m--> 251\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    252\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    256\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    257\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[1;32m    258\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    259\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[1;32m    260\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[1;32m    261\u001B[0m     )\n",
      "File \u001B[0;32m~/PycharmProjects/scientificProject1/.venv/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1500\u001B[0m, in \u001B[0;36mContext.call_function\u001B[0;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[1;32m   1498\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[1;32m   1499\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1500\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1501\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1503\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1504\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1505\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1506\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1507\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1508\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m   1509\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1510\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1514\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[1;32m   1515\u001B[0m   )\n",
      "File \u001B[0;32m~/PycharmProjects/scientificProject1/.venv/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def run_experiment(model):\n",
    "    optimizer = keras.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\n",
    "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    checkpoint_filepath = \"/tmp/checkpoint.weights.h5\"\n",
    "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_filepath,\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[checkpoint_callback],\n",
    "    )\n",
    "\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "\n",
    "history = run_experiment(vit_classifier)\n",
    "\n",
    "\n",
    "def plot_history(item):\n",
    "    plt.plot(history.history[item], label=item)\n",
    "    plt.plot(history.history[\"val_\" + item], label=\"val_\" + item)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(item)\n",
    "    plt.title(\"Train and Validation {} Over Epochs\".format(item), fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_history(\"loss\")\n",
    "plot_history(\"top-5-accuracy\")\n"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-29T09:26:14.061115130Z",
     "start_time": "2024-01-29T09:25:51.753539672Z"
    }
   },
   "id": "initial_id",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "da2336510a8f7176"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
