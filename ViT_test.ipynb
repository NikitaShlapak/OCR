{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Vit (from ofdocs)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60bfc8ae10e2d8f8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6f4f926052df5bb"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 11:46:50.668306: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-31 11:46:50.668357: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-31 11:46:50.669820: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-31 11:46:50.678368: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-31 11:46:52.222910: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": "('2.15.0', '3.0.0')"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import ops\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.__version__, keras.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T08:46:54.710180384Z",
     "start_time": "2024-01-31T08:46:50.091050684Z"
    }
   },
   "id": "9546a90916d06dfd",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Download data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49b087cd38ba6eee"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3) - y_train shape: (50000, 1)\n",
      "x_test shape: (10000, 32, 32, 3) - y_test shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "num_classes = 100\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T08:46:55.972836928Z",
     "start_time": "2024-01-31T08:46:54.680013863Z"
    }
   },
   "id": "d80cd6f23956f20a",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[255, 255, 255],\n        [255, 255, 255],\n        [255, 255, 255],\n        ...,\n        [195, 205, 193],\n        [212, 224, 204],\n        [182, 194, 167]],\n\n       [[255, 255, 255],\n        [254, 254, 254],\n        [254, 254, 254],\n        ...,\n        [170, 176, 150],\n        [161, 168, 130],\n        [146, 154, 113]],\n\n       [[255, 255, 255],\n        [254, 254, 254],\n        [255, 255, 255],\n        ...,\n        [189, 199, 169],\n        [166, 178, 130],\n        [121, 133,  87]],\n\n       ...,\n\n       [[148, 185,  79],\n        [142, 182,  57],\n        [140, 179,  60],\n        ...,\n        [ 30,  17,   1],\n        [ 65,  62,  15],\n        [ 76,  77,  20]],\n\n       [[122, 157,  66],\n        [120, 155,  58],\n        [126, 160,  71],\n        ...,\n        [ 22,  16,   3],\n        [ 97, 112,  56],\n        [141, 161,  87]],\n\n       [[ 87, 122,  41],\n        [ 88, 122,  39],\n        [101, 134,  56],\n        ...,\n        [ 34,  36,  10],\n        [105, 133,  59],\n        [138, 173,  79]]], dtype=uint8)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-31T08:47:05.851918297Z",
     "start_time": "2024-01-31T08:47:05.829480471Z"
    }
   },
   "id": "f1fe327937a19ee6",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setting parameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f824d82ccc0765f9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 64\n",
    "num_epochs = 10  # For real training, use num_epochs=100. 10 is a test value\n",
    "image_size = 32  # We'll resize input images to this size\n",
    "patch_size = 8  # Size of the patches to be extract from the input images\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "num_heads = 4\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]  # Size of the transformer layers\n",
    "transformer_layers = 4\n",
    "mlp_head_units = [\n",
    "    1024,\n",
    "    512,\n",
    "]  # Size of the dense layers of the final classifier\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T10:55:27.672143889Z",
     "start_time": "2024-01-30T10:55:27.669807988Z"
    }
   },
   "id": "9506089c0d74ea81",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tools"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "227db3147ecbadeb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data augmentation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "412f2431d38f2a4d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-30 13:55:27.730136: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-30 13:55:27.761750: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-30 13:55:27.762283: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-30 13:55:27.763884: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-30 13:55:27.764384: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-30 13:55:27.764630: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-30 13:55:27.861784: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-30 13:55:27.862005: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-30 13:55:27.862181: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-30 13:55:27.862328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1214 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Normalization(),\n",
    "        layers.Resizing(image_size, image_size),\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(factor=0.02),\n",
    "        layers.RandomZoom(height_factor=0.2, width_factor=0.2),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "# Compute the mean and the variance of the training data for normalization.\n",
    "data_augmentation.layers[0].adapt(x_train)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T10:55:28.333182821Z",
     "start_time": "2024-01-30T10:55:27.672945372Z"
    }
   },
   "id": "ad072d2ed7f9c576",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=keras.activations.gelu)(x)\n",
    "        x = layers.Dropout(dropout_rate)(x)\n",
    "    return x\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T10:55:28.336836343Z",
     "start_time": "2024-01-30T10:55:28.334140998Z"
    }
   },
   "id": "30f7ae2d6885a49d",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        input_shape = ops.shape(images)\n",
    "        batch_size = input_shape[0]\n",
    "        height = input_shape[1]\n",
    "        width = input_shape[2]\n",
    "        channels = input_shape[3]\n",
    "        num_patches_h = height // self.patch_size\n",
    "        num_patches_w = width // self.patch_size\n",
    "        patches = keras.ops.image.extract_patches(images, size=self.patch_size)\n",
    "        patches = ops.reshape(\n",
    "            patches,\n",
    "            (\n",
    "                batch_size,\n",
    "                num_patches_h * num_patches_w,\n",
    "                self.patch_size * self.patch_size * channels,\n",
    "            ),\n",
    "        )\n",
    "        return patches\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"patch_size\": self.patch_size})\n",
    "        return config\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T10:55:28.343677073Z",
     "start_time": "2024-01-30T10:55:28.337405250Z"
    }
   },
   "id": "8d0180dea9da238d",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualising Patches"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64168a64af6db8cb"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling Patches.call().\n\n\u001B[1mcannot compute Conv2D as input #1(zero-based) was expected to be a int32 tensor but is a float tensor [Op:Conv2D] name: \u001B[0m\n\nArguments received by Patches.call():\n  • images=tf.Tensor(shape=(1, 32, 32, 3), dtype=int32)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 9\u001B[0m\n\u001B[1;32m      4\u001B[0m plt\u001B[38;5;241m.\u001B[39maxis(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moff\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      6\u001B[0m resized_image \u001B[38;5;241m=\u001B[39m ops\u001B[38;5;241m.\u001B[39mimage\u001B[38;5;241m.\u001B[39mresize(\n\u001B[1;32m      7\u001B[0m     ops\u001B[38;5;241m.\u001B[39mconvert_to_tensor([image]), size\u001B[38;5;241m=\u001B[39m(image_size, image_size)\n\u001B[1;32m      8\u001B[0m )\n\u001B[0;32m----> 9\u001B[0m patches \u001B[38;5;241m=\u001B[39m \u001B[43mPatches\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpatch_size\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresized_image\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mImage size: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mimage_size\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m X \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mimage_size\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPatch size: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpatch_size\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m X \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpatch_size\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.local/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:123\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    120\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m    122\u001B[0m     \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m--> 123\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    125\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "Cell \u001B[0;32mIn[7], line 14\u001B[0m, in \u001B[0;36mPatches.call\u001B[0;34m(self, images)\u001B[0m\n\u001B[1;32m     12\u001B[0m num_patches_h \u001B[38;5;241m=\u001B[39m height \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpatch_size\n\u001B[1;32m     13\u001B[0m num_patches_w \u001B[38;5;241m=\u001B[39m width \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpatch_size\n\u001B[0;32m---> 14\u001B[0m patches \u001B[38;5;241m=\u001B[39m \u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextract_patches\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpatch_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     15\u001B[0m patches \u001B[38;5;241m=\u001B[39m ops\u001B[38;5;241m.\u001B[39mreshape(\n\u001B[1;32m     16\u001B[0m     patches,\n\u001B[1;32m     17\u001B[0m     (\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     21\u001B[0m     ),\n\u001B[1;32m     22\u001B[0m )\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m patches\n",
      "\u001B[0;31mInvalidArgumentError\u001B[0m: Exception encountered when calling Patches.call().\n\n\u001B[1mcannot compute Conv2D as input #1(zero-based) was expected to be a int32 tensor but is a float tensor [Op:Conv2D] name: \u001B[0m\n\nArguments received by Patches.call():\n  • images=tf.Tensor(shape=(1, 32, 32, 3), dtype=int32)"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 400x400 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "image = x_train[np.random.choice(range(x_train.shape[0]))]\n",
    "plt.imshow(image.astype(\"uint8\"))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "resized_image = ops.image.resize(\n",
    "    ops.convert_to_tensor([image]), size=(image_size, image_size)\n",
    ")\n",
    "patches = Patches(patch_size)(resized_image)\n",
    "print(f\"Image size: {image_size} X {image_size}\")\n",
    "print(f\"Patch size: {patch_size} X {patch_size}\")\n",
    "print(f\"Patches per image: {patches.shape[1]}\")\n",
    "print(f\"Elements per patch: {patches.shape[-1]}\")\n",
    "\n",
    "n = int(np.sqrt(patches.shape[1]))\n",
    "plt.figure(figsize=(4, 4))\n",
    "for i, patch in enumerate(patches[0]):\n",
    "    ax = plt.subplot(n, n, i + 1)\n",
    "    patch_img = ops.reshape(patch, (patch_size, patch_size, 3))\n",
    "    plt.imshow(ops.convert_to_numpy(patch_img).astype(\"uint8\"))\n",
    "    plt.axis(\"off\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T10:55:28.566761306Z",
     "start_time": "2024-01-30T10:55:28.345278317Z"
    }
   },
   "id": "c44d60dc928ace23",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "### PatchEncoder layer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f322a2f09c22a4e8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super().__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = ops.expand_dims(\n",
    "            ops.arange(start=0, stop=self.num_patches, step=1), axis=0\n",
    "        )\n",
    "        projected_patches = self.projection(patch)\n",
    "        encoded = projected_patches + self.position_embedding(positions)\n",
    "        return encoded\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"num_patches\": self.num_patches})\n",
    "        return config\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T10:55:36.010965990Z",
     "start_time": "2024-01-30T10:55:35.960955694Z"
    }
   },
   "id": "32de5912acf61eb0",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cdb358805da91d89"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[1mModel: \"functional_2\"\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001B[1m \u001B[0m\u001B[1mLayer (type)       \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape     \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mParam #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to        \u001B[0m\u001B[1m \u001B[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m, \u001B[38;5;34m32\u001B[0m, \u001B[38;5;34m3\u001B[0m) │       \u001B[38;5;34m0\u001B[0m │ -                    │\n│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ data_augmentation   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m32\u001B[0m, \u001B[38;5;34m32\u001B[0m, \u001B[38;5;34m3\u001B[0m) │       \u001B[38;5;34m7\u001B[0m │ input_layer[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]    │\n│ (\u001B[38;5;33mSequential\u001B[0m)        │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ patches_1 (\u001B[38;5;33mPatches\u001B[0m) │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m192\u001B[0m)   │       \u001B[38;5;34m0\u001B[0m │ data_augmentation[\u001B[38;5;34m0\u001B[0m… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ patch_encoder       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │  \u001B[38;5;34m13,376\u001B[0m │ patches_1[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]      │\n│ (\u001B[38;5;33mPatchEncoder\u001B[0m)      │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ layer_normalization │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │     \u001B[38;5;34m128\u001B[0m │ patch_encoder[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n│ (\u001B[38;5;33mLayerNormalizatio…\u001B[0m │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ multi_head_attenti… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │  \u001B[38;5;34m66,368\u001B[0m │ layer_normalization… │\n│ (\u001B[38;5;33mMultiHeadAttentio…\u001B[0m │                   │         │ layer_normalization… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ add (\u001B[38;5;33mAdd\u001B[0m)           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │       \u001B[38;5;34m0\u001B[0m │ multi_head_attentio… │\n│                     │                   │         │ patch_encoder[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]  │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ layer_normalizatio… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │     \u001B[38;5;34m128\u001B[0m │ add[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]            │\n│ (\u001B[38;5;33mLayerNormalizatio…\u001B[0m │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_1 (\u001B[38;5;33mDense\u001B[0m)     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m128\u001B[0m)   │   \u001B[38;5;34m8,320\u001B[0m │ layer_normalization… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_1 (\u001B[38;5;33mDropout\u001B[0m) │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m128\u001B[0m)   │       \u001B[38;5;34m0\u001B[0m │ dense_1[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]        │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_2 (\u001B[38;5;33mDense\u001B[0m)     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │   \u001B[38;5;34m8,256\u001B[0m │ dropout_1[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_2 (\u001B[38;5;33mDropout\u001B[0m) │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │       \u001B[38;5;34m0\u001B[0m │ dense_2[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]        │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ add_1 (\u001B[38;5;33mAdd\u001B[0m)         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │       \u001B[38;5;34m0\u001B[0m │ dropout_2[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m],     │\n│                     │                   │         │ add[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]            │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ layer_normalizatio… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │     \u001B[38;5;34m128\u001B[0m │ add_1[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]          │\n│ (\u001B[38;5;33mLayerNormalizatio…\u001B[0m │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ multi_head_attenti… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │  \u001B[38;5;34m66,368\u001B[0m │ layer_normalization… │\n│ (\u001B[38;5;33mMultiHeadAttentio…\u001B[0m │                   │         │ layer_normalization… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ add_2 (\u001B[38;5;33mAdd\u001B[0m)         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │       \u001B[38;5;34m0\u001B[0m │ multi_head_attentio… │\n│                     │                   │         │ add_1[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]          │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ layer_normalizatio… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │     \u001B[38;5;34m128\u001B[0m │ add_2[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]          │\n│ (\u001B[38;5;33mLayerNormalizatio…\u001B[0m │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_3 (\u001B[38;5;33mDense\u001B[0m)     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m128\u001B[0m)   │   \u001B[38;5;34m8,320\u001B[0m │ layer_normalization… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_4 (\u001B[38;5;33mDropout\u001B[0m) │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m128\u001B[0m)   │       \u001B[38;5;34m0\u001B[0m │ dense_3[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]        │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_4 (\u001B[38;5;33mDense\u001B[0m)     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │   \u001B[38;5;34m8,256\u001B[0m │ dropout_4[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_5 (\u001B[38;5;33mDropout\u001B[0m) │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │       \u001B[38;5;34m0\u001B[0m │ dense_4[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]        │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ add_3 (\u001B[38;5;33mAdd\u001B[0m)         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │       \u001B[38;5;34m0\u001B[0m │ dropout_5[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m],     │\n│                     │                   │         │ add_2[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]          │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ layer_normalizatio… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │     \u001B[38;5;34m128\u001B[0m │ add_3[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]          │\n│ (\u001B[38;5;33mLayerNormalizatio…\u001B[0m │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ multi_head_attenti… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │  \u001B[38;5;34m66,368\u001B[0m │ layer_normalization… │\n│ (\u001B[38;5;33mMultiHeadAttentio…\u001B[0m │                   │         │ layer_normalization… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ add_4 (\u001B[38;5;33mAdd\u001B[0m)         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │       \u001B[38;5;34m0\u001B[0m │ multi_head_attentio… │\n│                     │                   │         │ add_3[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]          │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ layer_normalizatio… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │     \u001B[38;5;34m128\u001B[0m │ add_4[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]          │\n│ (\u001B[38;5;33mLayerNormalizatio…\u001B[0m │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_5 (\u001B[38;5;33mDense\u001B[0m)     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m128\u001B[0m)   │   \u001B[38;5;34m8,320\u001B[0m │ layer_normalization… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_7 (\u001B[38;5;33mDropout\u001B[0m) │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m128\u001B[0m)   │       \u001B[38;5;34m0\u001B[0m │ dense_5[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]        │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_6 (\u001B[38;5;33mDense\u001B[0m)     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │   \u001B[38;5;34m8,256\u001B[0m │ dropout_7[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_8 (\u001B[38;5;33mDropout\u001B[0m) │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │       \u001B[38;5;34m0\u001B[0m │ dense_6[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]        │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ add_5 (\u001B[38;5;33mAdd\u001B[0m)         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │       \u001B[38;5;34m0\u001B[0m │ dropout_8[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m],     │\n│                     │                   │         │ add_4[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]          │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ layer_normalizatio… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │     \u001B[38;5;34m128\u001B[0m │ add_5[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]          │\n│ (\u001B[38;5;33mLayerNormalizatio…\u001B[0m │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ multi_head_attenti… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │  \u001B[38;5;34m66,368\u001B[0m │ layer_normalization… │\n│ (\u001B[38;5;33mMultiHeadAttentio…\u001B[0m │                   │         │ layer_normalization… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ add_6 (\u001B[38;5;33mAdd\u001B[0m)         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │       \u001B[38;5;34m0\u001B[0m │ multi_head_attentio… │\n│                     │                   │         │ add_5[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]          │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ layer_normalizatio… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │     \u001B[38;5;34m128\u001B[0m │ add_6[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]          │\n│ (\u001B[38;5;33mLayerNormalizatio…\u001B[0m │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_7 (\u001B[38;5;33mDense\u001B[0m)     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m128\u001B[0m)   │   \u001B[38;5;34m8,320\u001B[0m │ layer_normalization… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_10          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m128\u001B[0m)   │       \u001B[38;5;34m0\u001B[0m │ dense_7[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]        │\n│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_8 (\u001B[38;5;33mDense\u001B[0m)     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │   \u001B[38;5;34m8,256\u001B[0m │ dropout_10[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_11          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │       \u001B[38;5;34m0\u001B[0m │ dense_8[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]        │\n│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ add_7 (\u001B[38;5;33mAdd\u001B[0m)         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │       \u001B[38;5;34m0\u001B[0m │ dropout_11[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m],    │\n│                     │                   │         │ add_6[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]          │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ layer_normalizatio… │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m16\u001B[0m, \u001B[38;5;34m64\u001B[0m)    │     \u001B[38;5;34m128\u001B[0m │ add_7[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]          │\n│ (\u001B[38;5;33mLayerNormalizatio…\u001B[0m │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ flatten (\u001B[38;5;33mFlatten\u001B[0m)   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1024\u001B[0m)      │       \u001B[38;5;34m0\u001B[0m │ layer_normalization… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_12          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1024\u001B[0m)      │       \u001B[38;5;34m0\u001B[0m │ flatten[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]        │\n│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_9 (\u001B[38;5;33mDense\u001B[0m)     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1024\u001B[0m)      │ \u001B[38;5;34m1,049,…\u001B[0m │ dropout_12[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_13          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1024\u001B[0m)      │       \u001B[38;5;34m0\u001B[0m │ dense_9[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]        │\n│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_10 (\u001B[38;5;33mDense\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m512\u001B[0m)       │ \u001B[38;5;34m524,800\u001B[0m │ dropout_13[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_14          │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m512\u001B[0m)       │       \u001B[38;5;34m0\u001B[0m │ dense_10[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]       │\n│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_11 (\u001B[38;5;33mDense\u001B[0m)    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m100\u001B[0m)       │  \u001B[38;5;34m51,300\u001B[0m │ dropout_14[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]     │\n└─────────────────────┴───────────────────┴─────────┴──────────────────────┘\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\"> Param # </span>┃<span style=\"font-weight: bold\"> Connected to         </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>) │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ data_augmentation   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>) │       <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ patches_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Patches</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)   │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ data_augmentation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ patch_encoder       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">13,376</span> │ patches_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PatchEncoder</span>)      │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ patch_encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">66,368</span> │ layer_normalization… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │         │ layer_normalization… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attentio… │\n│                     │                   │         │ patch_encoder[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │   <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │   <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n│                     │                   │         │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">66,368</span> │ layer_normalization… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │         │ layer_normalization… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attentio… │\n│                     │                   │         │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │   <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │   <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n│                     │                   │         │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">66,368</span> │ layer_normalization… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │         │ layer_normalization… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attentio… │\n│                     │                   │         │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │   <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │   <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n│                     │                   │         │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">66,368</span> │ layer_normalization… │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │         │ layer_normalization… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ add_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attentio… │\n│                     │                   │         │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │   <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalization… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │   <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ add_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n│                     │                   │         │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalization… │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,…</span> │ dropout_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_13          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │ <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │ dropout_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dropout_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │         │                      │\n├─────────────────────┼───────────────────┼─────────┼──────────────────────┤\n│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">51,300</span> │ dropout_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n└─────────────────────┴───────────────────┴─────────┴──────────────────────┘\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m1,972,011\u001B[0m (7.52 MB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,972,011</span> (7.52 MB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m1,972,004\u001B[0m (7.52 MB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,972,004</span> (7.52 MB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m7\u001B[0m (32.00 B)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7</span> (32.00 B)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def create_vit_classifier():\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    # Augment data.\n",
    "    augmented = data_augmentation(inputs)\n",
    "    # Create patches.\n",
    "    patches = Patches(patch_size)(augmented)\n",
    "    # Encode patches.\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        # Skip connection 2.\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor.\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    representation = layers.Dropout(0.5)(representation)\n",
    "    # Add MLP.\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    # Classify outputs.\n",
    "    logits = layers.Dense(num_classes)(features)\n",
    "    # Create the Keras model.\n",
    "    model = keras.Model(inputs=inputs, outputs=logits)\n",
    "    return model\n",
    "vit_classifier = create_vit_classifier()\n",
    "vit_classifier.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T10:55:37.007829463Z",
     "start_time": "2024-01-30T10:55:36.799474456Z"
    }
   },
   "id": "829f6b5af2a51eb1",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Run"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1050709c31119a2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "def run_experiment(model):\n",
    "    optimizer = keras.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\n",
    "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top-5-accuracy\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    checkpoint_filepath = \"tmp/checkpoint.weights.h5\"\n",
    "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_filepath,\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[checkpoint_callback],\n",
    "    )\n",
    "\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "\n",
    "history = run_experiment(vit_classifier)\n",
    "\n",
    "\n",
    "def plot_history(item):\n",
    "    plt.plot(history.history[item], label=item)\n",
    "    plt.plot(history.history[\"val_\" + item], label=\"val_\" + item)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(item)\n",
    "    plt.title(\"Train and Validation {} Over Epochs\".format(item), fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_history(\"loss\")\n",
    "plot_history(\"top-5-accuracy\")\n"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2024-01-30T10:55:28.567063743Z"
    }
   },
   "id": "initial_id",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-30T10:55:28.567160445Z"
    }
   },
   "id": "da2336510a8f7176",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-30T10:55:28.567243781Z"
    }
   },
   "id": "5f572b9e882f8947"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
